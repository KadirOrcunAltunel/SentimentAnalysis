In this project, I performed a sentiment analysis in the finance domain using three different datasets. I also investigated the impact of class imbalance on sentiment analysis using various models, including logistic regression, XGBoost, BiLSTM, BERT, and RoBERTa. To address the challenges introduced by imbalanced datasets, I employed techniques like class_weight, sample_weight and focal loss which notably improved the F1-score of minority class.

My findings demonstrate that focusing solely on accuracy can be misleading in sentiment analysis, particularly when class imbalance exists. For example, while base RoBERTa achieved the highest accuracy across all the datasets, its performance on minority sentiment was not remarkable in dataset 1 compared to its counterpart optimized for class imbalance, highlighting the importance of evaluating models with metrics like F1- score which provide a more balanced assessment. These observations emphasize the need for careful tuning of hyperparameters and consideration of alternative performance metrics to avoid bias and ensure desirable model performance.

Future work could explore additional strategies to address class imbalance, such as utilizing data augmentation techniques like back translation, shuffling and word insertion. Moreover, fine-tuning BERT and RoBERTa with domain specific corpora can enhance the performance of the models by providing them better contextual understanding of specialized data.
